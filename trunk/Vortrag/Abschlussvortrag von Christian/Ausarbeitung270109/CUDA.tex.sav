\documentclass[twocolumn]{IEEEtran}
%\usepackage{epsf}
%\usepackage{./fit}
%\usepackage{./forms}
\usepackage[ansinew]{inputenc}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}
\kern-.08em T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\setcounter{page}{1}
\setlength\arraycolsep{1pt}

\newcommand{\fMm}{{\bf M}_{\rm m}}
\newcommand{\fMl}{{\bf M}_{\lambda}}

\begin{document}

\title{Wissenschaftliches Programmieren mit CUDA}
%
\thanks{\hrule}%
\thanks{Eingereicht am 05.02.2009}%
\thanks{Daniel Klimeck (Matnr. 6345768), Christian Renneke (Matnr. 6257603) }\\
\thanks{Universität Paderborn\\
FG Theoretische Elektrotechnik\\
Warburger Str. 100\\
33098 Paderborn\\
Germany
}
\thanks{Email: Daniel.Klimeck@tet.upb.de / Christian.Renneke@tet.upb.de}


\author{Daniel Klimeck und Christian Renneke}

\markboth{Ausarbeitung zum Projekt} {\it Wissenschaftliches Programmieren mit CUDA }%


\maketitle

\begin{abstract}
Das Projekt "`Wissenschaftliches Programmieren mit CUDA"' beschäftigte sich mit der Berechnung von Simulationen aus dem Bereich der theoretischen Elektrotechnik. Das Verarbeiten der Algorithmen sollte mit Hilfe der Rechenleistung einer Grafikkarte beschleunigt werden, um so die Simulationszeiten zu reduzieren. Die Implementierung erfolgte mittels CUDA ( Compute Unified Device Architecture ) von dem Unternehmen NVIDIA. Dabei handelt es sich um ein SDK ( Software Development Kit ) was die Programmierung der Grafikprozessoren von NVIDIA ermöglicht.
\end{abstract}


\section{Einführung}
Da bei der Verbesserung von Prozessoren die Erhöhung der Taktfrequenz an ihre wirtschaftlichen Grenzen stößt setzen die führenden Unternehmen auf parallele Verarbeitung. So werden aktuell vier Kerne in einer CPU genutzt, um mehr Rechenleistung zu erhalten.\\
Dieser Trend ist bei Grafikkarten bereits deutlich länger zu beobachten. Deren Prozessoren sind darauf ausgelegt immer ähnliche Operationen auf große Datenmengen anzuwenden. Dies lässt sich sehr gut parallelisieren, so dass in Grafikkarten meist mehrere Hundert parallele Prozessoren verarbeitet sind. Um diese hohe Rechenleistung nun auch für andere Zwecke als zur Bildverarbeitung Nutzen zu können hat NVIDIA ein SDK herausgebracht, dass es ermöglicht C- oder ??? Code auf der GPU auszuführen. Diese Technologie ist für alle von Interesse, die große Datenmengen auf ähnliche Weise verarbeiten und berechnen müssen, wie es zum Beispiel bei vielen Simulationen der Fall ist. \\
Daher sollte in diese Projektarbeit erarbeitet werden wie gut sich die Rechenleistung der GPUs nutzen lässt, um typische Simulationsaufgaben der theoretischen Elektrotechnik zu verkürzen.


------------------\\
GPUs und parallele berechnungen\\
Vorteile\\
nachteile\\
CUDA als Programmierumgebung \\
erwartete ergebnisse
\section{CUDA}
Programmierung unter C\\
Aufruf in Matlab üder MEX als Schnittstelle\\
Aufbau der Grafikkarten\\

\section{Simulationsbeispiel }
\subsection{Leapfrog-Algorithmus}

\subsection{Umsetzung in CUDA}
- Beispielcode
\section{Ergebnisse}
Vorstellung der Beispiele, Bragg Reflke
Diagramm
\section{Zusammenfassung}

-Lohnt es sich für große Beispiele
-Kostenreduzierend\\
\bibliographystyle{IEEE}

\begin{thebibliography}{9}

\bibitem{Hameyer}
J. Driesen, R. Belmans, K. Hameyer, ``Adaptive relaxation algorithms
for thermo-electromagnetic FEM problems'', IEEE Trans. on Magnetics,
Vol.\ 35, No.\ 3, 1999, pp.~1622-1625.

\bibitem{Kost}
L. J\"anicke, A. Kost, ``Convergence properties of of the Newton-Raphson
Method for nonlinear problems'', in Proc.  $\rm XI^{th}$ IEEE COMPUMAG,
Rio de Janeiro, Brazil, PF3-6, 1997, pp.~585-586.


\end{thebibliography}

\end{document}
