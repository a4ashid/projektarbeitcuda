#include "cuda.h"
#include <stdio.h>
#include "projektcuda.h"
#include "project_comm.h"
//#include "mex.h"
/* Kernel to square elements of the array on the GPU */
/*

	Matrix A is wA x wB  , Vector B is wB
	Vector C output vector in size of wB
	C=A*B
description:
	each row of A occuppy one block. if gridDim is smaller than the row number of A  
*/
__global__ void matrixMul( t_ve* C, t_ve* A, t_ve* B, int wA, int wB)
//__global__ void device_dotMul(t_ve* in1, t_ve* in2,t_ve* out, unsigned int N)
{
	

	//define a Result Vector for each block
	__shared__ float Cs[VECTOR_BLOCK_SIZE];//VECTOR_BLOCK_SIZE shuld equal blockDim
	
	//define gridIndex, if gridDim < wA, gridIndex > 0; 
	int gridIndex = 0;

	// get a thread indentifier
	int idx = blockIdx.x*blockDim.x+threadIdx.x;
	
	int subValue = 0;
	
	
	int aBegin = 0;
	int bBegin = 0;
	int a = aBegin;
	int b = bBegin;
	int aStep = gridDim.x;
	int bStep = VECTOR_BLOCK_SIZE; // blockDim.x
	int aEnd = wA;


	
	// if wB > gridDim???????
	for(int a = aBegin; (a < aEnd)&&(idx < wA*wB); a += aStep, gridIndex++){
		
		//initialize output vector for each block
		if(threadIdx.x==0){
			C[gridIndex*gridDim.x+blockIdx.x]=0;
		}
		__syncthreads();

		//following is operations within one block 
		// initialize the dot product for each row in A and vector B
		t_ve blocksum = 0;
		//if wB > blockDim, split repeat the  
		for(int b = bBegin; b < wB; b += bStep) {
			//initialise Cs 
			Cs[threadIdx.x] = 0;
			// compute scalar product
			if (( idx < wA*wB )&&(threadIdx.x < wB)) {
				Cs[threadIdx.x] = A[a + blockIdx.x ][b + threadIdx.x] * B[b + threadIdx.x ];
			}
			__syncthreads();
				
			if(threadIdx.x==0){
				for (int k = 1; k < VECTOR_BLOCK_SIZE; k++) Cs[0] += Cs[k];
				blocksum += Cs[0];
			}
			__syncthreads();
			
		}
		__syncthreads();
		if(threadIdx.x == 0) C[gridIndex*gridDim.x+blockIdx.x] = blocksum;
		__syncthreads();
		// summe all block
	
	}


}