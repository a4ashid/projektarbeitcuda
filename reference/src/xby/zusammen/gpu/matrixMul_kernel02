#include "cuda.h"
#include <stdio.h>
#include "projektcuda.h"
#include "project_comm.h"
//#include "mex.h"
/* Kernel to square elements of the array on the GPU */
__global__ void matrixMul( t_ve* C, t_ve* A, t_ve* B, int wA, int wB)
//__global__ void device_dotMul(t_ve* in1, t_ve* in2,t_ve* out, unsigned int N)
{
	//Matrix A is wA x wB, Vector B is wB

	//define a Result Vector for each block
	__shared__ float Cs[VECTOR_BLOCK_SIZE];
	// get a thread indentifier
	int idx = blockIdx.x*blockDim.x+threadIdx.x;
	
	int subValue = 0;
	//initialise Cs
	
	int aBegin = 0;
	int bBegin = 0;
	int a = aBegin;
	int b = bBegin;
	int aStep = bgridDim.x;
	int bStep = VECTOR_BLOCK_SIZE;

	//initialize output vector for each block
	if(threadIdx.x==0){
		out[blockIdx.x]=0;
	}
	__syncthreads();

	for(int a = aBegin; (a < wB)&&(idx < wA*wB); a += aStep){
		
		//following is operations within one block 
		t_ve blocksum = 0;
		for(int b = bBegin; b < wB; b += bStep) {
			Cs[threadIdx.x] = 0;
			// compute scalar product
			if (( idx < wA*wB )&&(threadIdx.x < wB)) {
				Cs[threadIdx.x] = A[a + blockIdx.x ][b + threadIdx.x] * B[b + threadIdx.x ];
			}
			__syncthreads();
				
			if(threadIdx.x==0){
				for (int k = 1; k < VECTOR_BLOCK_SIZE; k++) Cs[0] += Cs[k];
				blocksum += Cs[0];
			}
			__syncthreads();
			
		}

		// summe all block
	
	}
	/// summe all grid
	
	

	
	
	    
	


	
	//compute summe of all thread's results for each block 
	if(threadIdx.x==0){
	    for ( int i = 0; i < blockDim.x; i++ ) {
		     blocksum += Cs[i];
		}
		out[blockIdx.x]=blocksum;
	}
	__syncthreads();
	
	//compute the sume of all block's result for the grid
	if ( idx == 0 ) {
	     for ( int i = 1; i < gridDim.x; i++ ) {
		     out[0] += out[i];
		 }
	}

}